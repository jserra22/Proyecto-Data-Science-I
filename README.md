# An√°lisis de Supervivencia del Titanic con Machine Learning

Este proyecto final de Data Science I analiza el famoso conjunto de datos del Titanic. El objetivo principal es determinar qu√© factores demogr√°ficos y socioecon√≥micos influyeron m√°s en la probabilidad de supervivencia de los pasajeros, utilizando t√©cnicas de an√°lisis exploratorio y modelos de aprendizaje autom√°tico (Machine Learning).

## üìÑ Descripci√≥n del Proyecto

El hundimiento del Titanic es uno de los naufragios m√°s infames de la historia. Aunque hubo un elemento de suerte involucrado en sobrevivir, parece que algunos grupos de personas ten√≠an m√°s probabilidades de sobrevivir que otros.

Este an√°lisis busca responder: **¬øQu√© tipo de personas ten√≠an m√°s probabilidades de sobrevivir?**

El proyecto se divide en dos etapas principales:
1.  **An√°lisis Exploratorio de Datos (EDA):** Visualizaci√≥n y entendimiento de las variables.
2.  **Modelado Predictivo:** Entrenamiento de un algoritmo para predecir la supervivencia.

## üéØ Hip√≥tesis

> La probabilidad de supervivencia en el Titanic estuvo significativamente influenciada por factores demogr√°ficos, especialmente la edad y el g√©nero, reflejando decisiones de evacuaci√≥n y normas sociales de la √©poca (como "mujeres y ni√±os primero"). Adem√°s, se plantea que el estatus socioecon√≥mico actu√≥ como un filtro secundario.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

* **Python 3**
* **Pandas & NumPy:** Para la manipulaci√≥n y limpieza de datos.
* **Matplotlib & Seaborn:** Para la visualizaci√≥n de datos.
* **Scikit-Learn:** Para el preprocesamiento (LabelEncoder), selecci√≥n de caracter√≠sticas y el modelo de clasificaci√≥n (Random Forest).

## üöÄ Metodolog√≠a Aplicada

### 1. Preprocesamiento de Datos
* **Limpieza:** Se imputaron los valores nulos en `Age` y `Fare` utilizando la mediana para evitar sesgos por valores at√≠picos.
* **Codificaci√≥n:** Se transformaron variables categ√≥ricas como `Sex` a formato num√©rico (0/1) para su procesamiento matem√°tico.

### 2. Selecci√≥n de Caracter√≠sticas (Feature Selection)
Se utiliz√≥ la t√©cnica de **Feature Importance** mediante un modelo de Random Forest preliminar.
* **Variables Descartadas:** `Name`, `Ticket`, `Cabin`, `Embarked`, `SibSp`, `Parch` (por su baja influencia predictiva o alta cardinalidad).
* **Variables Seleccionadas:** `Pclass`, `Sex`, `Age`, `Fare`.

### 3. Modelo de Machine Learning
Se entren√≥ un **Random Forest Classifier** con la siguiente configuraci√≥n para asegurar generalizaci√≥n y evitar sobreajuste:
* `n_estimators`: 100
* `max_depth`: 5
* `test_size`: 20% (Validaci√≥n)

## üìä Resultados

El modelo final obtuvo los siguientes resultados en el conjunto de prueba:

* **Exactitud (Accuracy):** ~81%
* **Matriz de Confusi√≥n:** Mostr√≥ un buen balance entre sensibilidad y precisi√≥n, aunque con una ligera dificultad mayor para identificar falsos negativos en comparaci√≥n con los positivos.

## üìù Conclusiones

1.   **Validaci√≥n del Modelo**: El modelo de Random Forest alcanz√≥ una exactitud de aproximadamente el **81%**. Esto nos indica que es posible predecir la tasa de supervivencia de una forma fehaciente con tan solo 4 variables: Clase, G√©nero, Edad y Tarifa.

2.   **Confirmaci√≥n de Hip√≥tesis**: El uso de las variables G√©nero y Edad confirma que, estad√≠sticamente, la norma social de "mujeres y ni√±os primero" a la hora de evacuar la nave fue un factor determinante para la supervivencia de estos grupos.

3.   **Dimensi√≥n Socioecon√≥mica de la hip√≥tesis**: Las variables de Clase y Tarifa mostraron que los pasajeros con mayor poder adquisitivo tuvieron un acceso privilegiado a los botes salvavidas, actuando como un segundo filtro de supervivencia despu√©s del g√©nero.

---
**Autor:** Joaquin Serra
**Dataset:** Titanic - Machine Learning from Disaster (Kaggle)
